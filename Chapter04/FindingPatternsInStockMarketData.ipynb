{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how we can use unsupervised leanring for stock market analysis. We will operate\n",
    "with the assumption that we don't know how many clusters there are. As we don't know the\n",
    "number of clusters, we will use an algorithm called **Affinity Propagation** to cluster.\n",
    "It tries to find a representative datapoint for each cluster in our data. It tries to find\n",
    "measures of similarity between pairs of dadtapoints and considers all oru datapoints as\n",
    "potential representatives, also called **examplars**, of their respective clusters. You can\n",
    "learn more about it at http://www.cs.columbia.edu/~delbert/docs/DDueck-thesis_small.pdf.\n",
    "\n",
    "In this recipe, we will analyze the stock market variations of companies in a specified\n",
    "duration of time. Our goal is to then find out what companies behave similarly in terms of\n",
    "their quotes over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*quotes_historical_yahoo_ochl* is no longer available.  This python code will not be able to be run until a replacement data source is found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import covariance, cluster\n",
    "#from mplfinance import quotes_historical_yahoo_ochl as quotes_yahoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TOT': 'Total', 'XOM': 'Exxon', 'CVX': 'Chevron', 'COP': 'ConocoPhillips', 'VLO': 'Valero Energy', 'MSFT': 'Microsoft', 'IBM': 'IBM', 'TWX': 'Time Warner', 'CMCSA': 'Comcast', 'CVC': 'Cablevision', 'YHOO': 'Yahoo', 'DELL': 'Dell', 'HPQ': 'HP', 'AMZN': 'Amazon', 'TM': 'Toyota', 'CAJ': 'Canon', 'MTU': 'Mitsubishi', 'SNE': 'Sony', 'F': 'Ford', 'HMC': 'Honda', 'NAV': 'Navistar', 'NOC': 'Northrop Grumman', 'BA': 'Boeing', 'KO': 'Coca Cola', 'MMM': '3M', 'MCD': 'Mc Donalds', 'PEP': 'Pepsi', 'MDLZ': 'Kraft Foods', 'K': 'Kellogg', 'UN': 'Unilever', 'MAR': 'Marriott', 'PG': 'Procter Gamble', 'CL': 'Colgate-Palmolive', 'GE': 'General Electrics', 'WFC': 'Wells Fargo', 'JPM': 'JPMorgan Chase', 'AIG': 'AIG', 'AXP': 'American express', 'BAC': 'Bank of America', 'GS': 'Goldman Sachs', 'AAPL': 'Apple', 'SAP': 'SAP', 'CSCO': 'Cisco', 'TXN': 'Texas instruments', 'XRX': 'Xerox', 'LMT': 'Lookheed Martin', 'WMT': 'Wal-Mart', 'WBA': 'Walgreen', 'HD': 'Home Depot', 'GSK': 'GlaxoSmithKline', 'PFE': 'Pfizer', 'SNY': 'Sanofi-Aventis', 'NVS': 'Novartis', 'KMB': 'Kimberly-Clark', 'R': 'Ryder', 'GD': 'General Dynamics', 'RTN': 'Raytheon', 'CVS': 'CVS', 'CAT': 'Caterpillar', 'DD': 'DuPont de Nemours'}\n"
     ]
    }
   ],
   "source": [
    "# Load the symbols and the associated names\n",
    "symbol_file = 'symbol_map.json'\n",
    "\n",
    "# Load the symbol map\n",
    "with open(symbol_file, 'r') as f:\n",
    "    symbol_dict = json.loads(f.read())\n",
    "\n",
    "symbols, names = np.array(list(symbol_dict.items())).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a time period\n",
    "start_date = datetime.datetime(2004, 4, 5)\n",
    "end_date = datetime.datetime(2007, 6, 2)\n",
    "\n",
    "# Read the input data\n",
    "quotes = [quotes_yahoo(symbol, start_date, end_date, asobject=True) \n",
    "                for symbol in symbols]\n",
    "\n",
    "# Extract opening and closing quotes\n",
    "opening_quotes = np.array([quote.open for quote in quotes]).astype(np.float)\n",
    "closing_quotes = np.array([quote.close for quote in quotes]).astype(np.float)\n",
    "\n",
    "# The daily fluctuations of the quotes \n",
    "delta_quotes = closing_quotes - opening_quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a graph model from the correlations\n",
    "edge_model = covariance.GraphLassoCV()\n",
    "\n",
    "# Standardize the data \n",
    "X = delta_quotes.copy().T\n",
    "X /= X.std(axis=0)\n",
    "\n",
    "# Train the model\n",
    "with np.errstate(invalid='ignore'):\n",
    "    edge_model.fit(X)\n",
    "\n",
    "# Build clustering model using affinity propagation\n",
    "_, labels = cluster.affinity_propagation(edge_model.covariance_)\n",
    "num_labels = labels.max()\n",
    "\n",
    "# Print the results of clustering\n",
    "for i in range(num_labels + 1):\n",
    "    print (\"Cluster {} --> {}\".format(i+1, ', '.join(names[labels == i]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
