{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we discussed the k-means algorithm, we saw that we had to give the number of clusters\n",
    "as one of the input parameters. In the real world, we wouldn't have this information available.\n",
    "We can definitely sweep the parameter space to find out the optimal number of clustes using\n",
    "the silhouette coefficient score, but tht would be an expensive process! Wouldn't it be nice\n",
    "fi there were a method that can just tell us he number of clusters in our data? This is where\n",
    "**Density-Based Spatial Clustering of Applications with Noise (DBSCAN)** comes into the picture.\n",
    "\n",
    "This works by treating datapoints as groups of dense clusters. If a point belongs to a cluster,\n",
    "then there should be a lot of other points that belong to the same cluster. One of the\n",
    "parameters that we can control is the maximum distance of this point from other points. This\n",
    "is called **epsilon**. No two points in a given cluster should be further away that epsilon. You\n",
    "can learn more about it at https://en.wikipedia.org/wiki/DBSCAN. One of the main advantages of \n",
    "this method is that it can deal with outliers. If there are some points located alone in a \n",
    "low-density area, DBSCAN will detect these points as outliers as opposed to forcing them into\n",
    "a cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "from itertools import cycle\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utilities import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the input data\n",
    "input_file = 'data_perf.txt'\n",
    "X = load_data(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize variables to find the best epsilon\n",
    "eps_grid = np.linspace(0.3, 1.2, num=10)\n",
    "silhouette_scores = []\n",
    "eps_best = eps_grid[0]\n",
    "silhouette_score_max = -1\n",
    "model_best = None\n",
    "labels_best = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for eps in eps_grid:\n",
    "    # Train DBSCAN clustering model\n",
    "    model = DBSCAN(eps=eps, min_samples=5).fit(X)\n",
    "\n",
    "    # Extract labels\n",
    "    labels = model.labels_\n",
    "\n",
    "    # Extract performance metric \n",
    "    silhouette_score = round(metrics.silhouette_score(X, labels), 4)\n",
    "    silhouette_scores.append(silhouette_score)\n",
    "\n",
    "    print (\"Epsilon: %.1f  --> silhouette score: %.4f\"%(eps, silhouette_score))\n",
    "\n",
    "    # Store the best score and its associated epsilon value\n",
    "    if silhouette_score > silhouette_score_max:\n",
    "        silhouette_score_max = silhouette_score\n",
    "        eps_best = eps\n",
    "        model_best = model\n",
    "        labels_best = labels\n",
    "        \n",
    "# Best params\n",
    "print (\"\\nBest epsilon = %0.1f\"%(eps_best))\n",
    "\n",
    "# Associated model and labels for best epsilon\n",
    "model = model_best \n",
    "labels = labels_best\n",
    "\n",
    "# Check for unassigned datapoints in the labels\n",
    "offset = 0\n",
    "if -1 in labels:\n",
    "    offset = 1\n",
    "\n",
    "# Number of clusters in the data \n",
    "num_clusters = len(set(labels)) - offset \n",
    "\n",
    "print (\"\\nEstimated number of clusters =\", num_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot silhouette scores vs epsilon\n",
    "plt.figure()\n",
    "plt.bar(eps_grid, silhouette_scores, width=0.05, color='k', align='center')\n",
    "plt.title('Silhouette score vs epsilon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts the core samples from the trained model\n",
    "mask_core = np.zeros(labels.shape, dtype=np.bool)\n",
    "mask_core[model.core_sample_indices_] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot resultant clusters \n",
    "plt.figure()\n",
    "labels_uniq = set(labels)\n",
    "markers = cycle('vo^s<>')\n",
    "for cur_label, marker in zip(labels_uniq, markers):\n",
    "    # Use black dots for unassigned datapoints\n",
    "    if cur_label == -1:\n",
    "        marker = '.'\n",
    "\n",
    "    # Create mask for the current label\n",
    "    cur_mask = (labels == cur_label)\n",
    "\n",
    "    cur_data = X[cur_mask & mask_core]\n",
    "    plt.scatter(cur_data[:, 0], cur_data[:, 1], marker=marker,\n",
    "             edgecolors='black', s=96, facecolors='none')\n",
    "\n",
    "    cur_data = X[cur_mask & ~mask_core]\n",
    "    plt.scatter(cur_data[:, 0], cur_data[:, 1], marker=marker,\n",
    "             edgecolors='black', s=32)\n",
    "\n",
    "plt.title('Data separated into clusters')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
